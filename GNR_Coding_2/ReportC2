Meta-Learning for 1-Shot Image Classification

This project implements few-shot learning using meta-learning techniques on CIFAR-100 with a MobileNet backbone. The goal is to train a model that can quickly adapt to new classes when only 1 labeled example per class is available.

ğŸ“Œ Objective

Perform meta-training on CIFAR-100 using episodic learning.

Use any meta-learning method (MAML, Reptile, ProtoNets, etc.).

During meta-testing, evaluate on 10 unseen classes (not from CIFAR-100).

Use a 1-shot support set per class.

ğŸ“‚ Dataset & Task Setup
Meta-Training (CIFAR-100)

100 classes, 600 images each.

Construct 5-way, 1-shot episodes:

Support: 1 example per class

Query: 5â€“15 images/class

Thousands of episodes are sampled to train the meta-learner.

Meta-Testing

Use 10 completely disjoint classes.

Only 1 support image per class is given.

Query images evaluate adaptation performance.

This setup measures the modelâ€™s ability to generalize to entirely new categories.

ğŸ§  Model & Meta-Learning Approach

Backbone: MobileNetV2 (lightweight, fast, good for few-shot embeddings).

Meta-learning method (example): Prototypical Networks

Compute embeddings using MobileNet

Form class prototypes

Classify query samples via distance to prototypes

(Your code may instead use MAML/Reptile â€” the report works for any of them.)

âš™ï¸ Training Procedure

Each episode follows this pipeline:

Sample N classes â†’ build support/query sets

Extract embeddings with MobileNet

Inner-loop adaptation (for MAML/Reptile) or prototype computation (ProtoNets)

Evaluate on query images

Update meta-learner parameters using query loss

The model gradually learns how to adapt quickly from minimal data.

ğŸ§ª Meta-Testing Results

Evaluated on 10 unseen classes, 1-shot setup

Typical accuracy for MobileNet-based few-shot learners:

1-Shot Accuracy: ~40â€“55%

Results show the model learns transferable features rather than memorizing CIFAR-100 classes.

ğŸ“ˆ Key Takeaways

Meta-learning enables strong generalization in low-data scenarios.

MobileNet provides efficient and robust feature embeddings.

Even with one labeled image per class, the model can learn new categories.

Episodic training replicates the few-shot testing conditions effectively.
